{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "connected-patrick",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "relevant-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs_columns = np.arange(3, 11, 1)\n",
    "nbrs_shadow_datasets = [5000]*3 + [10000]* 5\n",
    "model_types = [ ('logreg', 'logreg'), ('mlptorch', 'mlptorch')]\n",
    "experiment_path = '../../experiments/randomized_target_attack/balanced_train_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "metallic-silence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model utility for 3 bins.\n",
      "\n",
      "n=3 variables\n",
      "logreg {'mean_test': 0.771, 'std_test': 0.113, 'mean_train': 0.773, 'std_train': 0.111}\n",
      "mlptorch {'mean_test': 0.76, 'std_test': 0.114, 'mean_train': 0.765, 'std_train': 0.11}\n",
      "\n",
      "n=4 variables\n",
      "logreg {'mean_test': 0.824, 'std_test': 0.101, 'mean_train': 0.827, 'std_train': 0.1}\n",
      "mlptorch {'mean_test': 0.807, 'std_test': 0.106, 'mean_train': 0.812, 'std_train': 0.104}\n",
      "\n",
      "n=5 variables\n",
      "logreg {'mean_test': 0.861, 'std_test': 0.087, 'mean_train': 0.864, 'std_train': 0.085}\n",
      "mlptorch {'mean_test': 0.834, 'std_test': 0.096, 'mean_train': 0.841, 'std_train': 0.094}\n",
      "\n",
      "n=6 variables\n",
      "logreg {'mean_test': 0.892, 'std_test': 0.072, 'mean_train': 0.894, 'std_train': 0.07}\n",
      "mlptorch {'mean_test': 0.86, 'std_test': 0.086, 'mean_train': 0.867, 'std_train': 0.084}\n",
      "\n",
      "n=7 variables\n",
      "logreg {'mean_test': 0.908, 'std_test': 0.061, 'mean_train': 0.912, 'std_train': 0.06}\n",
      "mlptorch {'mean_test': 0.874, 'std_test': 0.077, 'mean_train': 0.882, 'std_train': 0.076}\n",
      "\n",
      "n=8 variables\n",
      "logreg {'mean_test': 0.923, 'std_test': 0.055, 'mean_train': 0.926, 'std_train': 0.054}\n",
      "mlptorch {'mean_test': 0.885, 'std_test': 0.073, 'mean_train': 0.892, 'std_train': 0.073}\n",
      "\n",
      "n=9 variables\n",
      "logreg {'mean_test': 0.932, 'std_test': 0.049, 'mean_train': 0.935, 'std_train': 0.049}\n",
      "mlptorch {'mean_test': 0.893, 'std_test': 0.066, 'mean_train': 0.903, 'std_train': 0.065}\n",
      "\n",
      "n=10 variables\n",
      "logreg {'mean_test': 0.94, 'std_test': 0.042, 'mean_train': 0.944, 'std_train': 0.04}\n",
      "mlptorch {'mean_test': 0.902, 'std_test': 0.062, 'mean_train': 0.911, 'std_train': 0.06}\n"
     ]
    }
   ],
   "source": [
    "print('Model utility for 3 bins.')\n",
    "for ni, nbr_columns in enumerate(nbrs_columns):\n",
    "    print(f'\\nn={nbr_columns} variables')\n",
    "    model_results = dict()\n",
    "    for shadow_model_type, meta_model_type in model_types:\n",
    "        results_path = f'{experiment_path}/cols-{nbr_columns}/column/' + \\\n",
    "         f'seed_False_nt-1000_ns-{nbrs_shadow_datasets[ni]}_nds-1000_tts-0.3333_sts-0_ndsbb-100' + \\\n",
    "         f'_smt-{shadow_model_type}_mmt-{meta_model_type}_nb-3_sgf--1.pickle'\n",
    "        if not os.path.exists(results_path):\n",
    "            continue\n",
    "        with open(results_path, 'rb') as f:\n",
    "            results = pickle.load(f)\n",
    "            if (shadow_model_type == 'mlptorch' and not results['done']):\n",
    "                continue\n",
    "        model_results[shadow_model_type] = {'mean_test': np.round(np.mean(results['accs_target_test']), 3),\n",
    "                                           'std_test': np.round(np.std(results['accs_target_test']), 3),\n",
    "                                           'mean_train': np.round(np.mean(results['accs_target_train']), 3),\n",
    "                                           'std_train': np.round(np.std(results['accs_target_train']), 3)}\n",
    "    for key, value in model_results.items():\n",
    "        print(key, value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
